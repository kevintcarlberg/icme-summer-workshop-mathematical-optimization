---
layout: default
---

# Workshop Description

Mathematical optimization underpins many applications across science and
engineering, as it provides a set of formal tools to compute the ‘best’
action, design, control, or model from a set of possibilities. In data
science, machine learning, and artificial intelligence, mathematical
optimization is the engine of model training and learning. This workshop will
provide an overview of the key elements of this topic (unconstrained,
constrained, convex optimization, optimization for model training), and will
have a practical focus, with participants formulating and solving optimization
problems early and often using standard modeling languages and solvers. By
introducing common models from machine learning and other fields, this
workshop aims to make participants comfortable with optimization tools so that
they may use it for rapid prototyping and experimentation in their own work.
Students should be comfortable with linear algebra, differential multivariable
calculus, and basic probability and statistics. Experience with Python will be
helpful, but not required.

Topics to be discussed in this workshop include:

* Formulating optimization problems
* Fundamentals of constrained and unconstrained optimization
* Convex optimization
* Optimization methods for model fitting in machine learning
* Optimization in Python using SciPy and CVXPY
* In-depth Jupyter Notebook examples from machine learning, statistics, and other fields.

## About the Instructor

![Kevin Carlberg](/assets/img/profile.jpg){:style="max-width:30%;"}

[Kevin Carlberg](kevintcarlberg.net) is an AI Research Science Manager at Meta
Reality Labs and an Affiliate Associate Professor of Applied Mathematics and
Mechanical Engineering at the University of Washington. He leads a research
team focused on enabling the future of augmented and virtual reality through
AI-driven innovations. His individual research combines concepts from machine
learning, computational physics, and high-performance computing to drastically
reduce the cost of simulating nonlinear dynamical systems at extreme scale.
Previously, Kevin was a Distinguished Member of Technical Staff at Sandia
National Laboratories in Livermore, California, where he led a research group
of PhD students, postdocs, and technical staff in applying these techniques to
a range of national-security applications in mechanical and aerospace
engineering.

# Workshop Materials

## Pre-workshop Checklist

[Google Colab](https://colab.research.google.com/) is a free cloud-based
Jupyter Notebook environment. The Python Notebooks in this course’s shared
Drive contain real-world examples of optimization problems that you can
explore and study by running them using Google Colab. Here are the steps to
get started:
 
**Step 1: Add the shared Google Drive folder to your personal account** 

  - Go to [drive.google.com](drive.google.com) and log in with your Google
  account
- Go to [https://tinyurl.com/icmemathopt2022](https://tinyurl.com/icmemathopt2022) to access
  the shared Google Drive folder
- Click on "ICME Summer Workshop 2022 - Introduction to Mathematical Optimization" > "Add Shortcut to Drive".
 
**Step 2: Try out the Notebooks!**

  - In Google Drive, go to "ICME Summer Workshop 2022 - Introduction To Mathematical
  Optimization" > "Notebooks"
- Double click any notebook
- You now have three options:
  1. *Look at the notebook and its output*: Simply scroll around.
  2. *Interact with the notebook*: Feel free to modify the notebook and run it
     with modifications. However, because this remains part of the original folder, you
     do not have edit permissions and your changes won't be saved after
       exiting.
  3. *Make a copy of the notebook*: Click on “Copy to Drive” at the top, which will create a copy in "My Drive" > "Colab Notebooks". **This is your own separate copy.**

## Schedule

#### Session 1 (Friday, August 5, 1:00 - 2:30 P.M. PST)
  - Introduction to optimization
  - Unconstrained optimization

#### Session 2 (Friday, August 5, 2:45 - 4:00 P.M. PST)
  - Optimization in Python
  - Constrained optimization

#### Session 3 (Monday, August 8, 1:00 - 2:15 P.M. PST)
  - Optimization for machine learning

#### Session 4 (Monday, August 8, 2:30 - 4:00 P.M. PST)
  - Convex optimization
  - Convex optimization examples
	- Closing Q&A


## Additional Resources

Here are some additional resources for various topics:

- J. Nocedal and S. J. Wright. *Numerical Optimization*, Springer, 1999.
- S. Boyd and L. Vadenberghe. *Convex Optimization*, Cambridge University
  Press, 2004. [(available online)](http://stanford.edu/~boyd/cvxbook/)
  - Excellent lectures by S. Boyd online
  - Class notes and lectures for
    [EE364a](http://web.stanford.edu/class/ee364a/),
    [EE364b](http://web.stanford.edu/class/ee364b/) online
	- [CVX101 MOOC](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)
- P.E. Gill, W. Murray, and M.H. Wright, *Practical Optimization*, London,
  Academic Press, 1981.
- Bottou, L., Curtis, F.E. and Nocedal, J., 2018. Optimization methods for
  large-scale machine learning. SIAM Review, 60(2), pp.223-311. [(available on
  the arXiv)](https://arxiv.org/abs/1606.04838) (Advanced review article)
